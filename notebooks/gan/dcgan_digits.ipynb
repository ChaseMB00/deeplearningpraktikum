{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "85681fd2b3bda758"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:29.678123Z",
     "start_time": "2025-06-04T21:46:28.598641Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install imageio",
   "id": "4c4fbd147a79781d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in /opt/conda/lib/python3.12/site-packages (2.37.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from imageio) (1.26.4)\r\n",
      "Requirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.12/site-packages (from imageio) (11.1.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:32.949301Z",
     "start_time": "2025-06-04T21:46:29.942284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython import display"
   ],
   "id": "6267cf71b39294bd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 21:46:30.669108: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-04 21:46:30.690026: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-04 21:46:30.696355: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-04 21:46:30.713597: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-04 21:46:31.573458: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load the MNIST digits dataset\n",
    "We have to do a little bit of preprocessing to get the images into the right format for training. This part is different to the Fashion-MNIST dataset."
   ],
   "id": "a0e863414d29931f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:33.579588Z",
     "start_time": "2025-06-04T21:46:33.388426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "(mnist_images, mnist_labels), (mnist_images_test, mnist_labels_test) = keras.datasets.mnist.load_data()\n",
    "mnist_images.shape"
   ],
   "id": "6e76afe26d00ae92",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:33.728874Z",
     "start_time": "2025-06-04T21:46:33.726534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ],
   "id": "c83b00786ab85837",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:34.028964Z",
     "start_time": "2025-06-04T21:46:33.873316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(mnist_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ],
   "id": "c65e0fe34a0eaec3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 21:46:33.932063: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Define the Generator Model\n",
    "The generator model takes random noise as input and generates images. It uses transposed convolutional layers to upsample the noise into a 28x28 image."
   ],
   "id": "e42745c95b283622"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:34.264647Z",
     "start_time": "2025-06-04T21:46:34.258147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_generator_model():\n",
    "    model = keras.Sequential()\n",
    "    # Start with an Input layer as recommended\n",
    "    model.add(layers.Input(shape=(100,)))\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # Use Reshape instead of reshape\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "    return model"
   ],
   "id": "694b26a6e7bf8793",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generate an Image\n",
    "The following code generates a random image using the generator model. It creates a noise vector of shape (1, 100) and passes it through the generator to produce an image."
   ],
   "id": "69f96d8d126dd1a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:34.703257Z",
     "start_time": "2025-06-04T21:46:34.460783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ],
   "id": "a869e22f6e42dd3c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f023bb5bbf0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Define the Discriminator\n",
    "The discriminator is a convolutional neural network that classifies images as real (from the dataset) or fake (generated by the generator). It uses convolutional layers, LeakyReLU activations, and dropout for regularization."
   ],
   "id": "c2ddafac54fd9a50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:34.954579Z",
     "start_time": "2025-06-04T21:46:34.950542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_discriminator_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    return model"
   ],
   "id": "eda6fd543b78a75c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:35.282085Z",
     "start_time": "2025-06-04T21:46:35.212430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ],
   "id": "d62e7c836bade1c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00163518]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Define Loss Functions\n",
    "The loss function for the discriminator is binary cross-entropy, which measures how well the discriminator distinguishes between real and fake images. The generator's loss is also based on binary cross-entropy, where it tries to fool the discriminator into classifying generated images as real."
   ],
   "id": "2f192d87eb901124"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:35.463484Z",
     "start_time": "2025-06-04T21:46:35.459993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ],
   "id": "c87f00204efa5156",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:35.682651Z",
     "start_time": "2025-06-04T21:46:35.678861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ],
   "id": "7b1b32a5c33420db",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:35.867292Z",
     "start_time": "2025-06-04T21:46:35.863961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ],
   "id": "93599a7240bad642",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training Loop",
   "id": "ae2a2c8bebe0c1c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:36.053636Z",
     "start_time": "2025-06-04T21:46:36.049050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ],
   "id": "22142d21749ea331",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Training step\n",
    "The training step involves generating fake images from random noise, passing both real and fake images through the discriminator, calculating losses for both the generator and discriminator, and applying gradients to update their weights."
   ],
   "id": "21e73e4adb2d9e46"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:36.296733Z",
     "start_time": "2025-06-04T21:46:36.280227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ],
   "id": "af4d86e803f8b15e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Train the Model\n",
    "This function iterates through the dataset for a specified number of epochs, calling the `train_step` function for each batch of images. It also generates and saves images at the end of each epoch to visualize the generator's progress."
   ],
   "id": "31ff457fd4195cd7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:36.478503Z",
     "start_time": "2025-06-04T21:46:36.473752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "            #Produce Gif\n",
    "            display.clear_output(wait=True)\n",
    "            generate_and_save_images(generator, epoch + 1, seed)\n",
    "\n",
    "            print('Time taken for epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epochs, seed)"
   ],
   "id": "56c8e608afe1a4e1",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generate and Save Images\n",
    "This is just for visualization purposes. It generates images from the generator model and saves them to disk. The images are displayed in a grid format."
   ],
   "id": "a6b63f27c327cb64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:46:36.711390Z",
     "start_time": "2025-06-04T21:46:36.706471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ],
   "id": "d3111ddd92a26884",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "train(train_dataset, EPOCHS)",
   "id": "74c108472bf1c483",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Display a single image using the epoch number\n",
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ],
   "id": "8dd87b4fa12f5a16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "display_image(EPOCHS)",
   "id": "f93b2b2168263d6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create an animated GIF",
   "id": "5f0417d4158cdaa5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  for filename in filenames:\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)"
   ],
   "id": "8fd260711ad1bdd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)\n"
   ],
   "id": "bee8e22845c06d20"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
