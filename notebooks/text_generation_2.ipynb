{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-11T07:25:56.509919Z",
     "start_time": "2025-04-11T07:25:52.772213Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "path_to_file = keras.utils.get_file(\n",
    "        'shakespeare.txt',\n",
    "        'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
    "        )\n",
    "print(path_to_file)\n",
    "\n",
    "with open(path_to_file) as f:\n",
    "    shakespeare_text = f.read()\n",
    "print(shakespeare_text[:148])\n",
    "\n",
    "shakespeare_tensor = tf.constant([shakespeare_text])\n",
    "vocab = list(set(shakespeare_text.lower().strip()))\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True, lower=True)\n",
    "tokenizer.fit_on_texts(shakespeare_text.lower())\n",
    "n_tokens = len(tokenizer.word_index)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/thomasbayer/.keras/datasets/shakespeare.txt\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 09:25:56.146721: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2025-04-11 09:25:56.146738: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2025-04-11 09:25:56.146742: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1744356356.146756 9259612 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1744356356.146781 9259612 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T07:28:07.116821Z",
     "start_time": "2025-04-11T07:28:06.702155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model from the saved path\n",
    "model = load_model(\"models/shakespeare_gru_1.keras\")\n",
    "model.summary()\n"
   ],
   "id": "4683b590733e5140",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (\u001B[38;5;33mGRU\u001B[0m)                       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │        \u001B[38;5;34m64,896\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m39\u001B[0m)       │         \u001B[38;5;34m5,031\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">64,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,031</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m209,783\u001B[0m (819.47 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">209,783</span> (819.47 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m69,927\u001B[0m (273.15 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,927</span> (273.15 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m139,856\u001B[0m (546.32 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,856</span> (546.32 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T07:45:41.556857Z",
     "start_time": "2025-04-11T07:45:41.554413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"to be \"\n",
    "sequence = np.array(tokenizer.texts_to_sequences([text])[0])\n",
    "print(sequence)\n",
    "print(tokenizer.sequences_to_texts([sequence]))\n",
    "sequence = sequence - 1\n",
    "print(sequence)"
   ],
   "id": "653053382ae6ffa1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  4  1 22  2  1]\n",
      "['t o   b e  ']\n",
      "[ 2  3  0 21  1  0]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T07:38:12.962665Z",
     "start_time": "2025-04-11T07:38:12.955510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inp = tf.one_hot(sequence, depth=n_tokens)\n",
    "print(inp.shape)\n",
    "inp_tf = tf.reshape(inp, (1, 6, n_tokens))\n",
    "print(inp_tf.shape)\n"
   ],
   "id": "296f4ceadf32100b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 39)\n",
      "(1, 6, 39)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T07:41:30.803106Z",
     "start_time": "2025-04-11T07:41:30.759160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = model.predict(inp_tf)\n",
    "print(y.shape)\n",
    "prediction = y[0, -1, :]\n",
    "print(prediction.shape)"
   ],
   "id": "f4f94afe8283d8c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step\n",
      "(1, 6, 39)\n",
      "(39,)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T07:45:58.560581Z",
     "start_time": "2025-04-11T07:45:58.557380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "char_id = np.argmax(prediction) + 1\n",
    "print(char_id)\n",
    "\n",
    "sequence = np.append(sequence + 1, char_id)\n",
    "print(sequence)\n",
    "tokenizer.sequences_to_texts([sequence])"
   ],
   "id": "114d5fe3ab1c958",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  4  1 22  2  1  5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t o   b e   a']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T07:56:10.703731Z",
     "start_time": "2025-04-11T07:56:10.691843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def next_token(sequence, model, temperature=1, transform=None, argmax=True):\n",
    "    inp = transform(sequence) if transform else sequence\n",
    "\n",
    "\n",
    "one_hot_fn = lambda x: tf.one_hot(x, depth=n_tokens)\n",
    "sequence = np.array(tokenizer.texts_to_sequences([text])[0])\n",
    "sequence = sequence - 1\n",
    "next_token(sequence, model, transform=one_hot_fn)"
   ],
   "id": "ca122082f33b9fb",
   "outputs": [],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
