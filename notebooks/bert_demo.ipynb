{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-25T08:14:24.357167Z",
     "start_time": "2025-04-25T08:14:17.507849Z"
    }
   },
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "\n",
    "bert_tiny = 'google/bert_uncased_L-2_H-128_A-2'\n",
    "bert = AutoModel.from_pretrained(bert_tiny)\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_tiny)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:36:43.033126Z",
     "start_time": "2025-04-25T06:36:43.030094Z"
    }
   },
   "cell_type": "code",
   "source": "print(bert)",
   "id": "a67d9325f5501073",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 128)\n",
      "    (token_type_embeddings): Embedding(2, 128)\n",
      "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-1): 2 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSdpaSelfAttention(\n",
      "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:14:37.616883Z",
     "start_time": "2025-04-25T08:14:37.611234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inp = tokenizer(\"hallo welt\", return_tensors=\"pt\")\n",
    "print(inp)"
   ],
   "id": "82a2b92fba13571e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 2534, 2080, 2057, 7096,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:20:11.826001Z",
     "start_time": "2025-04-25T08:20:11.817820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = bert(inp['input_ids'], inp['attention_mask'])\n",
    "print(y.keys())"
   ],
   "id": "86eb91c77ddd9ffc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['last_hidden_state', 'pooler_output'])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:20:36.977448Z",
     "start_time": "2025-04-25T08:20:36.975321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(y['pooler_output'].shape)\n",
    "print(y['last_hidden_state'].shape)"
   ],
   "id": "b30a1320fa73abfb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "torch.Size([1, 6, 128])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:15:03.660781Z",
     "start_time": "2025-04-25T08:15:02.977187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mask_filler = pipeline(model=bert_tiny, task=\"fill-mask\")\n",
    "mask_filler(\"This is a [MASK] world.\")"
   ],
   "id": "803673d9b964b6ba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.0476624071598053,\n",
       "  'token': 2529,\n",
       "  'token_str': 'human',\n",
       "  'sequence': 'this is a human world.'},\n",
       " {'score': 0.03230414539575577,\n",
       "  'token': 2047,\n",
       "  'token_str': 'new',\n",
       "  'sequence': 'this is a new world.'},\n",
       " {'score': 0.0235151257365942,\n",
       "  'token': 2367,\n",
       "  'token_str': 'different',\n",
       "  'sequence': 'this is a different world.'},\n",
       " {'score': 0.02073436975479126,\n",
       "  'token': 2878,\n",
       "  'token_str': 'whole',\n",
       "  'sequence': 'this is a whole world.'},\n",
       " {'score': 0.017055684700608253,\n",
       "  'token': 2613,\n",
       "  'token_str': 'real',\n",
       "  'sequence': 'this is a real world.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
